{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"movies\").getOrCreate()\n",
    "\n",
    "# Load CSV file into DataFrame\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"C://Users//trebo//Desktop//BDAData//movies.csv\")\n",
    "\n",
    "# Show the first few rows\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Operations:\n",
    "# Data Filtering\n",
    "# Filter movies that are 2000 onwards and has a score of greater than or equal to 8\n",
    "df_filtered = df.filter((df[\"year\"] >= 2000) & (df[\"score\"] >= 8.0))\n",
    "df_filtered.show(10) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Columns\n",
    "# Selected columns are movie's respective name, its genre, lead star, head director and when\n",
    "# it was published.\n",
    "df_selected = df_filtered.select(\"name\", \"genre\", \"star\", \"director\", \"year\")\n",
    "df_selected.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "# 1. Remove rows where budget is null\n",
    "filtered_cleaning_bud = df_filtered.dropna(subset=[\"budget\"])\n",
    "\n",
    "# Show the cleaned dataset\n",
    "filtered_cleaning_bud.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Replace null or \"Unrated\" ratings with \"Not Rated\"\n",
    "filtered_cleaning_rat = filtered_cleaning_bud.withColumn(\n",
    "    \"rating\", when((col(\"rating\").isNull()) | (col(\"rating\") == \"Unrated\"), \"Not Rated\").otherwise(col(\"rating\"))\n",
    ")\n",
    "\n",
    "# Show the cleaned dataset\n",
    "filtered_cleaning_rat.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Remove rows where company is null\n",
    "filtered_cleaning_com = filtered_cleaning_rat.dropna(subset=[\"company\"])\n",
    "\n",
    "# Show the cleaned dataset\n",
    "filtered_cleaning_com.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Remove rows where gros score is null\n",
    "filtered_cleaning = filtered_cleaning_com.dropna(subset=[\"gross\"])\n",
    "\n",
    "# Show the cleaned dataset\n",
    "filtered_cleaning.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Queries\n",
    "# Register DataFrame as a Temporary Table\n",
    "filtered_cleaning.createOrReplaceTempView(\"movies_query\")\n",
    "\n",
    "# 1. Shows top 5 movies based on genre count\n",
    "query = \"\"\"\n",
    "SELECT genre, COUNT(*) as count \n",
    "FROM movies_query\n",
    "GROUP BY genre \n",
    "ORDER BY count DESC \n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "top_genres = spark.sql(query)\n",
    "top_genres.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Shows top 5 movies based on score\n",
    "query = \"\"\"\n",
    "SELECT name, score \n",
    "FROM movies_query \n",
    "ORDER BY score DESC \n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "top_movies = spark.sql(query)\n",
    "top_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Shows genre listed on the clean dataset \n",
    "query = \"\"\"\n",
    "SELECT DISTINCT genre\n",
    "FROM movies_query\n",
    "ORDER BY genre;\n",
    "\"\"\"\n",
    "\n",
    "unique_genres = spark.sql(query)\n",
    "unique_genres.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Shows top 3 movies for each genre based on gross score\n",
    "query = \"\"\"\n",
    "WITH GrossRanked AS (\n",
    "    SELECT \n",
    "        genre, \n",
    "        name, \n",
    "        gross,\n",
    "        ROW_NUMBER() OVER (PARTITION BY genre ORDER BY gross DESC) AS row_num\n",
    "    FROM movies_query\n",
    ")\n",
    "SELECT genre, name, gross\n",
    "FROM GrossRanked\n",
    "WHERE row_num <= 3\n",
    "ORDER BY genre, gross DESC;\n",
    "\"\"\"\n",
    "\n",
    "top3_grossing_per_genre = spark.sql(query)\n",
    "top3_grossing_per_genre.show(50)  # Show first 50 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark SQL for Operations\n",
    "# Data Filtering\n",
    "# Filters movies that are released on 2000 onwards and has a score of 8+\n",
    "filtered_movies = spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "    FROM movies_table\n",
    "    WHERE year >= 2000 AND score >= 8\n",
    "\"\"\")\n",
    "\n",
    "filtered_movies.show(5)  # Show first 10 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Grouping\n",
    "# Groups movies by genre and counts how many movies are in each genre\n",
    "genre_count = spark.sql(\"\"\"\n",
    "    SELECT genre, COUNT(*) AS movie_count\n",
    "    FROM movies_query\n",
    "    GROUP BY genre\n",
    "    ORDER BY movie_count DESC\n",
    "\"\"\")\n",
    "\n",
    "genre_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe results output:\n",
    "\n",
    "# Data to CSV File\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "cleaned_df = filtered_cleaning.toPandas()\n",
    "cleaned_df.to_csv(\"C:/Users/trebo/Desktop/BDAData/output/csv_output.csv\", index=False)\n",
    "\n",
    "print(\"File saved successfully as csv_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to JSON File\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "cleaned_df = filtered_cleaning.toPandas()\n",
    "\n",
    "# Save as a single JSON file\n",
    "cleaned_df.to_json(\"C:/Users/trebo/Desktop/BDAData/output/json_output.json\", \n",
    "                   orient=\"records\", indent=4)\n",
    "\n",
    "print(\"File saved successfully as json_output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to txt file\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "cleaned_df = filtered_cleaning.toPandas()\n",
    "\n",
    "# Format as a pretty table and save to TXT\n",
    "with open(\"C:/Users/trebo/Desktop/BDAData/output/txt_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(cleaned_df.to_string(index=False))\n",
    "\n",
    "print(\"File saved successfully as txt_output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
